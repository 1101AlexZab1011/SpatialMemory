{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "Linear = nn.Linear\n",
    "ConvTranspose2d = nn.ConvTranspose2d\n",
    "\n",
    "\n",
    "def Conv1d(*args, **kwargs):\n",
    "    layer = nn.Conv1d(*args, **kwargs)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def silu(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, max_steps):\n",
    "        super().__init__()\n",
    "        self.register_buffer('embedding', self._build_embedding(max_steps), persistent=False)\n",
    "        self.projection1 = Linear(128, 512)\n",
    "        self.projection2 = Linear(512, 512)\n",
    "\n",
    "    def forward(self, diffusion_step):\n",
    "        if diffusion_step.dtype in [torch.int32, torch.int64]:\n",
    "            x = self.embedding[diffusion_step]\n",
    "        else:\n",
    "            x = self._lerp_embedding(diffusion_step)\n",
    "        x = self.projection1(x)\n",
    "        x = silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = silu(x)\n",
    "        return x\n",
    "\n",
    "    def _lerp_embedding(self, t):\n",
    "        low_idx = torch.floor(t).long()\n",
    "        high_idx = torch.ceil(t).long()\n",
    "        low = self.embedding[low_idx]\n",
    "        high = self.embedding[high_idx]\n",
    "        return low + (high - low) * (t - low_idx)\n",
    "\n",
    "    def _build_embedding(self, max_steps):\n",
    "        steps = torch.arange(max_steps).unsqueeze(1)  # [T,1]\n",
    "        dims = torch.arange(64).unsqueeze(0)          # [1,64]\n",
    "        table = steps * 10.0**(dims * 4.0 / 63.0)     # [T,64]\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "\n",
    "\n",
    "class SpectrogramUpsampler(nn.Module):\n",
    "    def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = ConvTranspose2d(1, 1, [3, 32], stride=[1, 16], padding=[1, 8])\n",
    "            self.conv2 = ConvTranspose2d(1, 1,  [3, 32], stride=[1, 16], padding=[1, 8])\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            x = self.conv1(x)\n",
    "            x = F.leaky_relu(x, 0.4)\n",
    "            x = self.conv2(x)\n",
    "            x = F.leaky_relu(x, 0.4)\n",
    "            x = torch.squeeze(x, 1)\n",
    "            return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, n_mels, residual_channels, dilation, uncond=False):\n",
    "        '''\n",
    "        :param n_mels: inplanes of conv1x1 for spectrogram conditional\n",
    "        :param residual_channels: audio conv\n",
    "        :param dilation: audio conv dilation\n",
    "        :param uncond: disable spectrogram conditional\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.dilated_conv = Conv1d(residual_channels, 2 * residual_channels, 3, padding=dilation, dilation=dilation)\n",
    "        self.diffusion_projection = Linear(512, residual_channels)\n",
    "        if not uncond: # conditional model\n",
    "            self.conditioner_projection = Conv1d(n_mels, 2 * residual_channels, 1)\n",
    "        else: # unconditional model\n",
    "            self.conditioner_projection = None\n",
    "\n",
    "        self.output_projection = Conv1d(residual_channels, 2 * residual_channels, 1)\n",
    "\n",
    "    def forward(self, x, diffusion_step, conditioner=None):\n",
    "        assert (conditioner is None and self.conditioner_projection is None) or \\\n",
    "            (conditioner is not None and self.conditioner_projection is not None)\n",
    "\n",
    "        diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
    "        y = x + diffusion_step\n",
    "        if self.conditioner_projection is None: # using a unconditional model\n",
    "            y = self.dilated_conv(y)\n",
    "        else:\n",
    "            conditioner = self.conditioner_projection(conditioner)\n",
    "            y = self.dilated_conv(y) + conditioner\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "\n",
    "        y = self.output_projection(y)\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        return (x + residual) / sqrt(2.0), skip\n",
    "\n",
    "\n",
    "class DiffWave(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.input_projection = Conv1d(1, params.residual_channels, 1)\n",
    "        self.diffusion_embedding = DiffusionEmbedding(len(params.noise_schedule))\n",
    "        if self.params.unconditional: # use unconditional model\n",
    "            self.spectrogram_upsampler = None\n",
    "        else:\n",
    "            self.spectrogram_upsampler = SpectrogramUpsampler(params.n_mels)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList([\n",
    "            ResidualBlock(params.n_mels, params.residual_channels, 2**(i % params.dilation_cycle_length), uncond=params.unconditional)\n",
    "            for i in range(params.residual_layers)\n",
    "        ])\n",
    "        self.skip_projection = Conv1d(params.residual_channels, params.residual_channels, 1)\n",
    "        self.output_projection = Conv1d(params.residual_channels, 1, 1)\n",
    "        nn.init.zeros_(self.output_projection.weight)\n",
    "\n",
    "    def forward(self, audio, diffusion_step, spectrogram=None):\n",
    "        assert (spectrogram is None and self.spectrogram_upsampler is None) or \\\n",
    "            (spectrogram is not None and self.spectrogram_upsampler is not None)\n",
    "        x = audio.unsqueeze(1)\n",
    "        x = self.input_projection(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        diffusion_step = self.diffusion_embedding(diffusion_step)\n",
    "        if self.spectrogram_upsampler: # use conditional model\n",
    "            spectrogram = self.spectrogram_upsampler(spectrogram)\n",
    "\n",
    "        skip = None\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_step, spectrogram)\n",
    "            skip = skip_connection if skip is None else skip_connection + skip\n",
    "\n",
    "        x = skip / sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output_projection(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, residual_channels: int, dilation: int, n_mels: int = None):\n",
    "        super().__init__()\n",
    "        self.dilated_conv = Conv1d(\n",
    "            residual_channels,\n",
    "            2 * residual_channels,\n",
    "            3,\n",
    "            padding=dilation,\n",
    "            dilation=dilation\n",
    "        )\n",
    "        self.diffusion_projection = Linear(512, residual_channels)\n",
    "\n",
    "        if n_mels is not None: # conditional model\n",
    "            self.conditioner_projection = Conv1d(n_mels, 2 * residual_channels, 1)\n",
    "        else: # unconditional model\n",
    "            self.conditioner_projection = None\n",
    "\n",
    "        self.output_projection = Conv1d(residual_channels, 2 * residual_channels, 1)\n",
    "\n",
    "    def forward(self, x, diffusion_step, conditioner=None):\n",
    "        assert (conditioner is None and self.conditioner_projection is None) or \\\n",
    "            (conditioner is not None and self.conditioner_projection is not None)\n",
    "\n",
    "        diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
    "        y = x + diffusion_step\n",
    "        if self.conditioner_projection is None: # using a unconditional model\n",
    "            y = self.dilated_conv(y)\n",
    "        else:\n",
    "            conditioner = self.conditioner_projection(conditioner)\n",
    "            y = self.dilated_conv(y) + conditioner\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "\n",
    "        y = self.output_projection(y)\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        return (x + residual) / sqrt(2.0), skip\n",
    "\n",
    "\n",
    "class DiffWave1D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        residual_channels: int,\n",
    "        n_residual_layers: int,\n",
    "        dilation_cycle_length: int,\n",
    "        diffusion_embedding: DiffusionEmbedding,\n",
    "        n_mels: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.residual_channels = residual_channels\n",
    "        self.diffusion_embedding = diffusion_embedding\n",
    "        self.n_mels = n_mels\n",
    "        self.spectrogram_upsampler = SpectrogramUpsampler() if self.n_mels is not None else None\n",
    "\n",
    "        self.input_projection = nn.Conv1d(1, self.residual_channels, 1)\n",
    "        self.output_projection = nn.Conv1d(self.residual_channels, 1, 1)\n",
    "        nn.init.zeros_(self.output_projection.weight) # zero init for output projection\n",
    "        self.residual_layers = nn.ModuleList([\n",
    "            ResidualBlock(params.n_mels, params.residual_channels, 2**(i % params.dilation_cycle_length), uncond=params.unconditional)\n",
    "            for i in range(params.residual_layers)\n",
    "        ])\n",
    "        self.skip_projection = Conv1d(params.residual_channels, params.residual_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, audio, diffusion_step, spectrogram=None):\n",
    "        assert (spectrogram is None and self.spectrogram_upsampler is None) or \\\n",
    "            (spectrogram is not None and self.spectrogram_upsampler is not None)\n",
    "        x = audio.unsqueeze(1)\n",
    "        x = self.input_projection(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        diffusion_step = self.diffusion_embedding(diffusion_step)\n",
    "        if self.spectrogram_upsampler: # use conditional model\n",
    "            spectrogram = self.spectrogram_upsampler(spectrogram)\n",
    "\n",
    "        skip = None\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_step, spectrogram)\n",
    "            skip = skip_connection if skip is None else skip_connection + skip\n",
    "\n",
    "        x = skip / sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output_projection(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "            super(AttrDict, self).__init__(*args, **kwargs)\n",
    "            self.__dict__ = self\n",
    "\n",
    "    def override(self, attrs):\n",
    "        if isinstance(attrs, dict):\n",
    "            self.__dict__.update(**attrs)\n",
    "        elif isinstance(attrs, (list, tuple, set)):\n",
    "            for attr in attrs:\n",
    "                self.override(attr)\n",
    "        elif attrs is not None:\n",
    "            raise NotImplementedError\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AttrDict(\n",
    "    # Training params\n",
    "    batch_size=16,\n",
    "    learning_rate=2e-4,\n",
    "    max_grad_norm=None,\n",
    "\n",
    "    # Data params\n",
    "    sample_rate=22050,\n",
    "    n_mels=80,\n",
    "    n_fft=1024,\n",
    "    hop_samples=256,\n",
    "    crop_mel_frames=62,  # Probably an error in paper.\n",
    "\n",
    "    # Model params\n",
    "    residual_layers=30,\n",
    "    residual_channels=64,\n",
    "    dilation_cycle_length=10,\n",
    "    unconditional = False,\n",
    "    noise_schedule=np.linspace(1e-4, 0.05, 50).tolist(),\n",
    "    inference_noise_schedule=[0.0001, 0.001, 0.01, 0.05, 0.2, 0.5],\n",
    "\n",
    "    # unconditional sample len\n",
    "    audio_len = 22050*5, # unconditional_synthesis_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'learning_rate': 0.0002,\n",
       " 'max_grad_norm': None,\n",
       " 'sample_rate': 22050,\n",
       " 'n_mels': 80,\n",
       " 'n_fft': 1024,\n",
       " 'hop_samples': 256,\n",
       " 'crop_mel_frames': 62,\n",
       " 'residual_layers': 30,\n",
       " 'residual_channels': 64,\n",
       " 'dilation_cycle_length': 10,\n",
       " 'unconditional': False,\n",
       " 'noise_schedule': [0.0001,\n",
       "  0.0011183673469387756,\n",
       "  0.002136734693877551,\n",
       "  0.0031551020408163264,\n",
       "  0.004173469387755102,\n",
       "  0.005191836734693878,\n",
       "  0.006210204081632653,\n",
       "  0.007228571428571429,\n",
       "  0.008246938775510203,\n",
       "  0.009265306122448979,\n",
       "  0.010283673469387754,\n",
       "  0.01130204081632653,\n",
       "  0.012320408163265305,\n",
       "  0.013338775510204081,\n",
       "  0.014357142857142857,\n",
       "  0.015375510204081632,\n",
       "  0.016393877551020408,\n",
       "  0.017412244897959183,\n",
       "  0.01843061224489796,\n",
       "  0.019448979591836734,\n",
       "  0.02046734693877551,\n",
       "  0.021485714285714285,\n",
       "  0.02250408163265306,\n",
       "  0.023522448979591836,\n",
       "  0.02454081632653061,\n",
       "  0.025559183673469387,\n",
       "  0.026577551020408163,\n",
       "  0.027595918367346938,\n",
       "  0.028614285714285714,\n",
       "  0.02963265306122449,\n",
       "  0.030651020408163265,\n",
       "  0.031669387755102044,\n",
       "  0.03268775510204082,\n",
       "  0.033706122448979595,\n",
       "  0.03472448979591837,\n",
       "  0.035742857142857146,\n",
       "  0.03676122448979592,\n",
       "  0.0377795918367347,\n",
       "  0.03879795918367347,\n",
       "  0.03981632653061225,\n",
       "  0.04083469387755102,\n",
       "  0.0418530612244898,\n",
       "  0.042871428571428574,\n",
       "  0.04388979591836735,\n",
       "  0.044908163265306125,\n",
       "  0.0459265306122449,\n",
       "  0.046944897959183676,\n",
       "  0.04796326530612245,\n",
       "  0.04898163265306123,\n",
       "  0.05],\n",
       " 'inference_noise_schedule': [0.0001, 0.001, 0.01, 0.05, 0.2, 0.5],\n",
       " 'audio_len': 110250}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Module for performing Diffusion Embedding based on specified parameters.\n",
    "\n",
    "    Implements an architecture that utilizes a learned embedding for diffusion steps.\n",
    "\n",
    "    Args:\n",
    "        max_steps (int): The maximum number of diffusion steps.\n",
    "        embedding_dim (int): The dimension of the diffusion embedding (default is 64).\n",
    "        diffusion_dim (int): The dimension of the diffusion process (default is 512).\n",
    "\n",
    "    Attributes:\n",
    "        max_steps (int): The maximum number of diffusion steps.\n",
    "        embedding_dim (int): The dimension of the diffusion embedding.\n",
    "        diffusion_dim (int): The dimension of the diffusion process.\n",
    "        embedding (Tensor): The precomputed embedding for diffusion steps.\n",
    "        input_projection (Linear): Input projection layer.\n",
    "        output_projection (Linear): Output projection layer.\n",
    "\n",
    "    Methods:\n",
    "        _build_embedding(): Builds the diffusion embedding table based on the max_steps and embedding_dim.\n",
    "        _lerp_embedding(t: float): Performs linear interpolation for the diffusion embedding at a specific time step.\n",
    "        forward(diffusion_step: int | float): Forward pass through the diffusion embedding model.\n",
    "\n",
    "    References:\n",
    "        Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).\n",
    "        \"Attention is All you Need.\" arXiv (Cornell University), 30, 5998–6008.\n",
    "        [https://arxiv.org/pdf/1706.03762v5](https://arxiv.org/pdf/1706.03762v5)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_steps: int,\n",
    "        embedding_dim: int = 64,\n",
    "        diffusion_dim: int = 512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.max_steps = max_steps\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.diffusion_dim = diffusion_dim\n",
    "        self.register_buffer('embedding', self._build_embedding(), persistent=False)\n",
    "        self.input_projection = Linear(self.embedding_dim*2, self.diffusion_dim)\n",
    "        self.output_projection = Linear(self.diffusion_dim, self.diffusion_dim)\n",
    "\n",
    "    def _build_embedding(self):\n",
    "        \"\"\"\n",
    "        Builds the diffusion embedding based on the maximum steps and embedding dimension.\n",
    "        Generates the embedding table using sinusoidal functions.\n",
    "        \"\"\"\n",
    "        steps = torch.arange(self.max_steps).unsqueeze(1)  # [T,1]\n",
    "        dims = torch.arange(self.embedding_dim).unsqueeze(0)          # [1,D_e]\n",
    "        table = steps * 10.0**(dims * 4.0 / (self.embedding_dim - 1))     # [T,D_e]\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "\n",
    "    def _lerp_embedding(self, t: float):\n",
    "        \"\"\"\n",
    "        Performs linear interpolation for the diffusion embedding at a specific time step (t).\n",
    "        Utilizes the precomputed embedding table to interpolate values for non-integer time steps.\n",
    "        \"\"\"\n",
    "        low_idx = torch.floor(t).long()\n",
    "        high_idx = torch.ceil(t).long()\n",
    "        low = self.embedding[low_idx]\n",
    "        high = self.embedding[high_idx]\n",
    "        return low + (high - low) * (t - low_idx)\n",
    "\n",
    "    def forward(self, diffusion_step: int | float):\n",
    "        \"\"\"\n",
    "        Forward pass through the diffusion embedding model.\n",
    "\n",
    "        Args:\n",
    "            diffusion_step (int | float): The diffusion step for which to compute the embedding.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output tensor resulting from the diffusion embedding process.\n",
    "        \"\"\"\n",
    "        if isinstance(diffusion_step, (int, torch.int32, torch.int64)):\n",
    "            x = self.embedding[diffusion_step]\n",
    "        else:\n",
    "            x = self._lerp_embedding(diffusion_step)\n",
    "        x = self.input_projection(x)\n",
    "        x = nn.functional.silu(x)\n",
    "        x = self.output_projection(x)\n",
    "        x = nn.functional.silu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = DiffusionEmbedding(100)\n",
    "embedding(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramUpsampler(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Module for upsampling spectrogram data using transpose convolutional layers.\n",
    "\n",
    "    Args:\n",
    "        n_channels (int): Number of input and output channels (default is 1).\n",
    "        kernel_size (tuple[int, int]): Size of the convolutional kernel (default is (3, 32)).\n",
    "        stride (tuple[int, int]): Stride value for the convolutional operation (default is (1, 16)).\n",
    "        padding (tuple[int, int]): Padding applied to the input tensor (default is (1, 8)).\n",
    "        negative_slope (float): Slope value for the LeakyReLU activation (default is 0.4).\n",
    "        n_layers (int): Number of upsampling layers (default is 2).\n",
    "\n",
    "    Attributes:\n",
    "        upsampler (Sequential): Sequential module consisting of ConvTranspose2d layers followed by LeakyReLU.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Performs a forward pass through the upsampler module.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels: int = 1,\n",
    "        kernel_size: tuple[int, int] = (3, 32),\n",
    "        stride: tuple[int, int] = (1, 16),\n",
    "        padding: tuple[int, int] = (1, 8),\n",
    "        negative_slope=0.4,\n",
    "        n_layers: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsampler = nn.Sequential(\n",
    "            *(\n",
    "                nn.Sequential(\n",
    "                    ConvTranspose2d(n_channels, n_channels, kernel_size, stride, padding),\n",
    "                    nn.LeakyReLU(negative_slope),\n",
    "                ) for _ in range(n_layers)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Performs an upsampling operation on the input tensor using transpose convolutional layers.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor representing the spectrogram data.\n",
    "                        Shape should be n_batch x n_channels x n_mel_frames x n_mel_bins.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor after the upsampling operation.\n",
    "        \"\"\"\n",
    "        # x.shape ~ n_batch x n_channels x n_mel_frames x n_mel_bins\n",
    "        x = self.upsampler(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 16, 20480])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updampler = SpectrogramUpsampler(n_channels=2)\n",
    "spectrogram = torch.randn(10, 2, 16, 80)\n",
    "upsampled = updampler(spectrogram)\n",
    "upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Module for a residual block in a DiffWave model.\n",
    "\n",
    "    Args:\n",
    "        n_residual_channels (int): Number of residual channels in the block.\n",
    "        dilation (int): Dilation value for the convolutional layers.\n",
    "        kernel (int, optional): Kernel size for dilated convolution (default is 3).\n",
    "        diffusion_dim (int, optional): Dimension for diffusion projection (default is 512).\n",
    "        n_mels (int, optional): Number of Mel-spectrogram channels. If None, unconditional model is used (default is None).\n",
    "        n_conditional_channels (int, optional): Number of channels for conditional melspectrogram (default is 1).\n",
    "\n",
    "    Attributes:\n",
    "        dilated_conv (Conv1d): Dilated convolutional layer in the residual block.\n",
    "        diffusion_projection (Linear): Projection layer for diffusion dimension.\n",
    "        conditioner_projection (Conv2d or None): Conditional projection layer (None for unconditional model).\n",
    "        output_projection (Conv1d): Output projection layer for the residual block.\n",
    "\n",
    "    Methods:\n",
    "        forward(x, diffusion_step, conditioner=None): Performs a forward pass through the residual block.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_residual_channels: int,\n",
    "        dilation: int,\n",
    "        kernel: int = 3,\n",
    "        diffusion_dim: int = 512,\n",
    "        n_mels: int = None,\n",
    "        n_conditional_channels: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dilated_conv = nn.Conv1d(\n",
    "            n_residual_channels,\n",
    "            2 * n_residual_channels,\n",
    "            kernel,\n",
    "            padding='same',\n",
    "            dilation=dilation\n",
    "        )\n",
    "        self.diffusion_projection = Linear(diffusion_dim, n_residual_channels)\n",
    "\n",
    "        if n_mels is not None: # conditional model\n",
    "            self.conditioner_projection = nn.Conv2d(n_mels, 2 * n_residual_channels, (n_conditional_channels, 1))\n",
    "        else: # unconditional model\n",
    "            self.conditioner_projection = None\n",
    "\n",
    "        self.output_projection = nn.Conv1d(n_residual_channels, 2 * n_residual_channels, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        diffusion_step: torch.Tensor,\n",
    "        conditioner: torch.Tensor = None\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Performs the forward pass through the ResidualBlock.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to the block.\n",
    "            diffusion_step (torch.Tensor): Tensor representing the diffusion step.\n",
    "            conditioner (torch.Tensor, optional): Conditioning tensor for the model (default is None).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: Tuple of the output and the intermediate skip connection.\n",
    "\n",
    "        \"\"\"\n",
    "        if (conditioner is None) != (self.conditioner_projection is None):\n",
    "            raise ValueError('Conditioner and projection should be both None or not None')\n",
    "\n",
    "        diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
    "        y = x + diffusion_step\n",
    "\n",
    "        if self.conditioner_projection is None: # using a unconditional model\n",
    "            y = self.dilated_conv(y)\n",
    "        else:\n",
    "            y = self.dilated_conv(y) + torch.squeeze(self.conditioner_projection(conditioner), 2)\n",
    "\n",
    "        gate, filter_ = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter_)\n",
    "        y = self.output_projection(y)\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        return (x + residual) / sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 20, 100]), torch.Size([10, 20, 100]))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(10, 20, 100)\n",
    "embedding = DiffusionEmbedding(100)\n",
    "res_layer = ResidualBlock(20, 1)\n",
    "x, skip = res_layer(X, embedding(10))\n",
    "x.shape, skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 20, 101]), torch.Size([10, 20, 101]))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(10, 20, 101)\n",
    "x, skip = res_layer(X, embedding(10))\n",
    "x.shape, skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16, 1, 25600])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 20, 25600]), torch.Size([10, 20, 25600]))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updampler = SpectrogramUpsampler(n_channels=1)\n",
    "spectrogram = torch.randn(10, 1, 16, 100)\n",
    "upsampled = updampler(spectrogram)\n",
    "X = torch.randn(10, 20, 25600)\n",
    "upsampled = torch.permute(upsampled, (0, 2, 1, 3))\n",
    "print(upsampled.shape)\n",
    "\n",
    "embedding = DiffusionEmbedding(100)\n",
    "x, skip = ResidualBlock(20, 1, n_mels=16, n_conditional_channels=1)(X, embedding(10), upsampled)\n",
    "x.shape, skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 40, 100]) torch.Size([10, 40, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 20, 100]), torch.Size([10, 20, 100]))"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(10, 20, 100)\n",
    "embedding = DiffusionEmbedding(100)\n",
    "spectrogram = torch.randn(10, 16, 1, 100)\n",
    "\n",
    "x, skip = ResidualBlock(20, 1, n_mels=16, n_conditional_channels=1)(X, embedding(10), spectrogram)\n",
    "x.shape, skip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ConditionerParams:\n",
    "    \"\"\"\n",
    "    Data class defining parameters for the conditioner model.\n",
    "\n",
    "    Args:\n",
    "        n_mels (int): Number of mel-frequency bands.\n",
    "        upsampler (SpectrogramUpsampler): Spectrogram upsampler for the conditioner model (default is SpectrogramUpsampler).\n",
    "        n_channels (int): Number of input channels (default is 1).\n",
    "        kernel (tuple[int, int]): Size of the convolutional kernel (default is (3, 32)).\n",
    "        stride (tuple[int, int]): Stride value for the convolutional operation (default is (1, 16)).\n",
    "        padding (tuple[int, int]): Padding applied to the input tensor (default is (1, 8)).\n",
    "        negative_slope (float): Slope value for the LeakyReLU activation (default is 0.4).\n",
    "        n_layers (int): Number of upsampling layers (default is 2).\n",
    "\n",
    "    Attributes:\n",
    "        n_mels (int): Number of mel-frequency bands.\n",
    "        upsampler (SpectrogramUpsampler): Spectrogram upsampler instance.\n",
    "        n_channels (int): Number of input channels for the conditioner model.\n",
    "        kernel (tuple[int, int]): Size of the convolutional kernel.\n",
    "        stride (tuple[int, int]): Stride value for the convolutional operation.\n",
    "        padding (tuple[int, int]): Padding applied to the input tensor.\n",
    "        negative_slope (float): Slope value for the LeakyReLU activation.\n",
    "        n_layers (int): Number of upsampling layers.\n",
    "\n",
    "    Methods:\n",
    "        __post_init__(): Initializes the upsampler instance using the provided parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    n_mels: int\n",
    "    upsampler: SpectrogramUpsampler = SpectrogramUpsampler\n",
    "    n_channels: int = 1\n",
    "    kernel: tuple[int, int] = (3, 32)\n",
    "    stride: tuple[int, int] = (1, 16)\n",
    "    padding: tuple[int, int] = (1, 8)\n",
    "    negative_slope: float = 0.4\n",
    "    n_layers: int = 2\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.upsampler = self.upsampler(\n",
    "            kernel_size=self.kernel,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            negative_slope=self.negative_slope,\n",
    "            n_layers=self.n_layers,\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class ResidualParams:\n",
    "    \"\"\"\n",
    "    Data class defining parameters for the residual blocks.\n",
    "\n",
    "    Args:\n",
    "        n_residual_layers (int): Number of residual layers.\n",
    "        n_residual_channels (int): Number of channels for the residual blocks.\n",
    "        dilation_cycle_length (int): Length of the dilation cycle.\n",
    "        kernel (int): Size of the convolutional kernel (default is 3).\n",
    "        conditioner (ConditionerParams): Conditioner parameters (default is None).\n",
    "\n",
    "    Attributes:\n",
    "        n_residual_layers (int): Number of residual layers.\n",
    "        n_residual_channels (int): Number of channels for the residual blocks.\n",
    "        dilation_cycle_length (int): Length of the dilation cycle.\n",
    "        kernel (int): Size of the convolutional kernel.\n",
    "        conditioner (ConditionerParams): Conditioner parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    n_residual_layers: int\n",
    "    n_residual_channels: int\n",
    "    dilation_cycle_length: int\n",
    "    kernel: int = 3\n",
    "    conditioner: ConditionerParams = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiffusionParams:\n",
    "    \"\"\"\n",
    "    Data class defining parameters for the diffusion model.\n",
    "\n",
    "    Args:\n",
    "        max_steps (int): Maximum number of steps in diffusion.\n",
    "        embedding_dim (int): Dimension for the embedding (default is 64).\n",
    "        diffusion_dim (int): Dimension for diffusion (default is 512).\n",
    "        embedding (DiffusionEmbedding): Embedding instance for diffusion.\n",
    "\n",
    "    Attributes:\n",
    "        max_steps (int): Maximum number of steps in diffusion.\n",
    "        embedding_dim (int): Dimension for the embedding.\n",
    "        diffusion_dim (int): Dimension for diffusion.\n",
    "        embedding (DiffusionEmbedding): Embedding instance for diffusion.\n",
    "\n",
    "    Methods:\n",
    "        __post_init__(): Initializes the embedding instance using the provided parameters.\n",
    "\n",
    "    \"\"\"\n",
    "    max_steps: int\n",
    "    embedding_dim: int = 64\n",
    "    diffusion_dim: int = 512\n",
    "    embedding: DiffusionEmbedding = DiffusionEmbedding\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.embedding = self.embedding(self.max_steps, self.embedding_dim, self.diffusion_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiffWave(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Module for a DiffWave model implementing diffusion probabilistic models.\n",
    "\n",
    "    Args:\n",
    "        input_channels (int): Number of input channels.\n",
    "        diffusion_params (DiffusionParams): Parameters for the diffusion process.\n",
    "        residual_params (ResidualParams): Parameters for the residual blocks.\n",
    "\n",
    "    Attributes:\n",
    "        input_channels (int): Number of input channels for the model.\n",
    "        diffusion_params (DiffusionParams): Parameters for the diffusion process.\n",
    "        residual_params (ResidualParams): Parameters for the residual blocks.\n",
    "        diffusion_embedding: The diffusion embedding to be used in the model.\n",
    "        spectrogram_upsampler: Upsampler for the input spectrogram.\n",
    "        input_projection (Conv1d): Input projection layer.\n",
    "        output_projection (Conv1d): Output projection layer.\n",
    "        residual_layers (ModuleList): List of residual blocks in the model.\n",
    "        skip_projection (Conv1d): Projection for skip connection.\n",
    "\n",
    "    Methods:\n",
    "        forward(input_, diffusion_step, spectrogram=None): Performs a forward pass through the DiffWave model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        diffusion_params: DiffusionParams,\n",
    "        residual_params: ResidualParams\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.diffusion_params = diffusion_params\n",
    "        self.residual_params = residual_params\n",
    "\n",
    "        self.diffusion_embedding = self.diffusion_params.embedding\n",
    "        self.spectrogram_upsampler = None if self.residual_params.conditioner is None\\\n",
    "            else self.residual_params.conditioner.upsampler\n",
    "\n",
    "        self.input_projection = nn.Conv1d(\n",
    "            self.input_channels,\n",
    "            self.residual_params.n_residual_channels,\n",
    "            1\n",
    "        )\n",
    "        self.output_projection = nn.Conv1d(\n",
    "            self.residual_params.n_residual_channels,\n",
    "            self.input_channels,\n",
    "            1\n",
    "        )\n",
    "        nn.init.zeros_(self.output_projection.weight) # zero init for output projection\n",
    "\n",
    "        if self.residual_params.conditioner is not None:\n",
    "            n_mels = self.residual_params.conditioner.n_mels\n",
    "            n_channels = self.residual_params.conditioner.n_channels\n",
    "        else:\n",
    "            n_mels = None\n",
    "            n_channels = 1\n",
    "\n",
    "        self.residual_layers = nn.ModuleList([\n",
    "            ResidualBlock(\n",
    "                self.residual_params.n_residual_channels,\n",
    "                2**(i % self.residual_params.dilation_cycle_length),\n",
    "                self.residual_params.kernel,\n",
    "                self.diffusion_params.diffusion_dim,\n",
    "                n_mels, n_channels\n",
    "            )\n",
    "            for i in range(self.residual_params.n_residual_layers)\n",
    "        ])\n",
    "\n",
    "        self.skip_projection = Conv1d(\n",
    "            self.residual_params.n_residual_channels,\n",
    "            self.residual_params.n_residual_channels,\n",
    "            1\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_: torch.Tensor,\n",
    "        diffusion_step: int | float,\n",
    "        spectrogram: torch.Tensor = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the DiffWave model.\n",
    "\n",
    "        Args:\n",
    "            input_ (torch.Tensor): Input tensor to the model.\n",
    "            diffusion_step (int | float): Tensor representing the diffusion step.\n",
    "            spectrogram (torch.Tensor, optional): Spectrogram tensor (default is None).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after the forward pass.\n",
    "        \"\"\"\n",
    "        if (spectrogram is None) != (self.spectrogram_upsampler is None):\n",
    "            if (spectrogram is None):\n",
    "                raise ValueError('Conditioner is required for conditional model')\n",
    "            else:\n",
    "                raise ValueError('Conditioner is provided, but the model is unconditional')\n",
    "\n",
    "\n",
    "        x = input_.unsqueeze(1)\n",
    "        x = self.input_projection(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        diffusion_step = self.diffusion_embedding(diffusion_step)\n",
    "        if self.spectrogram_upsampler: # use conditional model\n",
    "            spectrogram = self.spectrogram_upsampler(spectrogram)\n",
    "            spectrogram = torch.permute(spectrogram, (0, 2, 1, 3))\n",
    "\n",
    "        skip = None\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_step, spectrogram)\n",
    "            skip = skip_connection if skip is None else skip_connection + skip\n",
    "\n",
    "        x = skip / sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output_projection(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_params = ResidualParams(\n",
    "    n_residual_layers=10,\n",
    "    n_residual_channels=64,\n",
    "    dilation_cycle_length=10,\n",
    ")\n",
    "diffusion_params = DiffusionParams(\n",
    "    max_steps=100\n",
    ")\n",
    "\n",
    "diffwave = DiffWave(1, diffusion_params, residual_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0780, 0.0913, 0.0657, 0.0949, 0.0802, 0.0968, 0.0743, 0.0636,\n",
       "          0.0756, 0.0757, 0.0717, 0.0552, 0.0718, 0.0663, 0.0656, 0.0658,\n",
       "          0.0582, 0.0669, 0.0754, 0.0788, 0.0751, 0.0847, 0.0687, 0.0923,\n",
       "          0.0809, 0.0889, 0.0803, 0.0700, 0.0859, 0.0811, 0.0905, 0.0793,\n",
       "          0.0812, 0.0905, 0.0919, 0.0794, 0.1245, 0.0820, 0.0775, 0.1109,\n",
       "          0.0716, 0.1059, 0.0487, 0.0697, 0.0848, 0.0799, 0.0781, 0.0915,\n",
       "          0.0811, 0.0986, 0.1290, 0.0772, 0.1087, 0.0916, 0.0741, 0.1024,\n",
       "          0.1104, 0.0714, 0.0790, 0.0946, 0.1059, 0.0745, 0.0863, 0.0847,\n",
       "          0.0713, 0.0595, 0.0999, 0.0965, 0.0465, 0.0986, 0.0991, 0.0727,\n",
       "          0.0872, 0.1201, 0.0880, 0.1083, 0.0810, 0.0809, 0.1102, 0.0857,\n",
       "          0.0738, 0.0729, 0.1044, 0.0624, 0.0710, 0.0834, 0.0667, 0.0712,\n",
       "          0.0843, 0.0818, 0.0607, 0.0847, 0.0973, 0.0640, 0.0793, 0.1169,\n",
       "          0.1027, 0.0708, 0.0921, 0.0875]],\n",
       "\n",
       "        [[0.0497, 0.0673, 0.0689, 0.0638, 0.1037, 0.0857, 0.0851, 0.1156,\n",
       "          0.0720, 0.0797, 0.0906, 0.0986, 0.0613, 0.0832, 0.0890, 0.0752,\n",
       "          0.0563, 0.0976, 0.1066, 0.0611, 0.0914, 0.0873, 0.0896, 0.0634,\n",
       "          0.0726, 0.0843, 0.0584, 0.0631, 0.0882, 0.0725, 0.0548, 0.0906,\n",
       "          0.0923, 0.0700, 0.1119, 0.0920, 0.0900, 0.1046, 0.0922, 0.0857,\n",
       "          0.1317, 0.0799, 0.0732, 0.0885, 0.0936, 0.0910, 0.0697, 0.0811,\n",
       "          0.0718, 0.1128, 0.0977, 0.0614, 0.0864, 0.0906, 0.0725, 0.0899,\n",
       "          0.0887, 0.0767, 0.0901, 0.0738, 0.0952, 0.1141, 0.0725, 0.0819,\n",
       "          0.0810, 0.0839, 0.0699, 0.0760, 0.0689, 0.0460, 0.0698, 0.0971,\n",
       "          0.0750, 0.0742, 0.0972, 0.0823, 0.0901, 0.1168, 0.0818, 0.0900,\n",
       "          0.0638, 0.0958, 0.1057, 0.0725, 0.0615, 0.0739, 0.0729, 0.0757,\n",
       "          0.0828, 0.0681, 0.0552, 0.0775, 0.1180, 0.0869, 0.0783, 0.0810,\n",
       "          0.0870, 0.1104, 0.1039, 0.0650]],\n",
       "\n",
       "        [[0.0448, 0.0436, 0.0565, 0.0736, 0.0865, 0.0768, 0.0676, 0.0755,\n",
       "          0.1013, 0.0862, 0.0649, 0.0879, 0.0599, 0.0653, 0.0911, 0.0960,\n",
       "          0.0784, 0.0642, 0.0648, 0.0777, 0.0831, 0.0699, 0.0731, 0.0583,\n",
       "          0.0902, 0.0950, 0.0681, 0.1079, 0.0985, 0.0776, 0.0929, 0.1126,\n",
       "          0.0549, 0.0814, 0.1102, 0.0508, 0.0598, 0.0891, 0.1129, 0.0649,\n",
       "          0.0974, 0.0859, 0.0943, 0.0888, 0.0800, 0.0777, 0.0620, 0.0575,\n",
       "          0.0886, 0.0870, 0.0528, 0.0872, 0.1043, 0.0824, 0.0749, 0.0941,\n",
       "          0.0736, 0.1069, 0.0759, 0.0773, 0.1011, 0.0951, 0.0789, 0.0754,\n",
       "          0.1066, 0.0740, 0.0844, 0.0848, 0.0931, 0.0861, 0.1081, 0.0876,\n",
       "          0.1144, 0.0973, 0.0718, 0.1454, 0.0816, 0.0697, 0.0954, 0.0974,\n",
       "          0.0634, 0.0779, 0.0741, 0.0920, 0.0861, 0.0886, 0.0788, 0.0693,\n",
       "          0.1116, 0.0788, 0.0730, 0.0811, 0.0718, 0.1000, 0.0932, 0.0631,\n",
       "          0.1130, 0.1020, 0.0780, 0.0747]],\n",
       "\n",
       "        [[0.0668, 0.0834, 0.0517, 0.0631, 0.0780, 0.1000, 0.0939, 0.0809,\n",
       "          0.0986, 0.0746, 0.0845, 0.0759, 0.0838, 0.0775, 0.0712, 0.0681,\n",
       "          0.0828, 0.0905, 0.0907, 0.1171, 0.0645, 0.1032, 0.1024, 0.0760,\n",
       "          0.0969, 0.0960, 0.0637, 0.0734, 0.0957, 0.0817, 0.0548, 0.0720,\n",
       "          0.0900, 0.0645, 0.0865, 0.1092, 0.0796, 0.0807, 0.1365, 0.0673,\n",
       "          0.0771, 0.1476, 0.0880, 0.0779, 0.0972, 0.1023, 0.0733, 0.0901,\n",
       "          0.0744, 0.0687, 0.0725, 0.0447, 0.0686, 0.0813, 0.0978, 0.0600,\n",
       "          0.0844, 0.1276, 0.0765, 0.1178, 0.0718, 0.0871, 0.0735, 0.0934,\n",
       "          0.0734, 0.0640, 0.0653, 0.0753, 0.0888, 0.0714, 0.1383, 0.0763,\n",
       "          0.0748, 0.1105, 0.0911, 0.0922, 0.0772, 0.1088, 0.0688, 0.0908,\n",
       "          0.0935, 0.1011, 0.0612, 0.0855, 0.0915, 0.0697, 0.0846, 0.0676,\n",
       "          0.1009, 0.0507, 0.0617, 0.0980, 0.1061, 0.0660, 0.1033, 0.1273,\n",
       "          0.0991, 0.0981, 0.0993, 0.0973]],\n",
       "\n",
       "        [[0.0741, 0.0810, 0.0714, 0.0714, 0.1087, 0.0781, 0.0875, 0.0971,\n",
       "          0.0806, 0.0883, 0.0977, 0.0896, 0.0576, 0.0815, 0.0881, 0.0723,\n",
       "          0.0797, 0.0683, 0.0668, 0.0883, 0.0926, 0.0718, 0.0752, 0.0624,\n",
       "          0.0631, 0.0623, 0.0683, 0.0542, 0.0561, 0.0643, 0.0676, 0.0778,\n",
       "          0.0756, 0.0784, 0.0777, 0.0862, 0.0980, 0.0853, 0.0611, 0.0617,\n",
       "          0.0537, 0.0535, 0.0541, 0.0559, 0.0740, 0.0914, 0.0579, 0.0829,\n",
       "          0.1002, 0.0964, 0.0841, 0.0782, 0.0678, 0.0860, 0.0976, 0.0650,\n",
       "          0.0725, 0.0798, 0.0929, 0.0819, 0.0864, 0.1104, 0.0827, 0.1057,\n",
       "          0.1008, 0.0803, 0.1012, 0.1004, 0.0788, 0.0801, 0.0906, 0.0767,\n",
       "          0.0805, 0.0739, 0.0837, 0.0963, 0.0844, 0.0749, 0.0980, 0.1074,\n",
       "          0.0734, 0.1164, 0.1226, 0.0582, 0.0850, 0.1150, 0.0889, 0.0514,\n",
       "          0.0757, 0.0793, 0.0914, 0.0683, 0.0723, 0.0892, 0.0953, 0.0693,\n",
       "          0.0748, 0.0837, 0.0643, 0.0684]],\n",
       "\n",
       "        [[0.0705, 0.0877, 0.0524, 0.0773, 0.1159, 0.0789, 0.0946, 0.0743,\n",
       "          0.0869, 0.0824, 0.0918, 0.0707, 0.0707, 0.0848, 0.0690, 0.0722,\n",
       "          0.0721, 0.0788, 0.0658, 0.0871, 0.0737, 0.0730, 0.1063, 0.0768,\n",
       "          0.0666, 0.0943, 0.0717, 0.0777, 0.1170, 0.0517, 0.0874, 0.1143,\n",
       "          0.0802, 0.0900, 0.0905, 0.0710, 0.0819, 0.1015, 0.0536, 0.0591,\n",
       "          0.0733, 0.0772, 0.0625, 0.0766, 0.0814, 0.0763, 0.0953, 0.0678,\n",
       "          0.0723, 0.0836, 0.0833, 0.0629, 0.0610, 0.0699, 0.0665, 0.0821,\n",
       "          0.0725, 0.0689, 0.0858, 0.0939, 0.0926, 0.0589, 0.0843, 0.0759,\n",
       "          0.0612, 0.0871, 0.0773, 0.0547, 0.0781, 0.0781, 0.0700, 0.1051,\n",
       "          0.0979, 0.0921, 0.1130, 0.0920, 0.1171, 0.1021, 0.0904, 0.0570,\n",
       "          0.0971, 0.1126, 0.0622, 0.0837, 0.0822, 0.1328, 0.0988, 0.0836,\n",
       "          0.0986, 0.1036, 0.0552, 0.0906, 0.0916, 0.0711, 0.0582, 0.0602,\n",
       "          0.1000, 0.0796, 0.0700, 0.0836]],\n",
       "\n",
       "        [[0.0993, 0.0426, 0.0779, 0.1092, 0.0891, 0.0810, 0.0809, 0.0862,\n",
       "          0.0821, 0.0880, 0.0744, 0.0673, 0.0515, 0.0739, 0.0890, 0.0643,\n",
       "          0.0871, 0.0629, 0.0976, 0.1126, 0.0730, 0.0836, 0.1082, 0.0658,\n",
       "          0.0641, 0.1006, 0.0784, 0.0603, 0.0769, 0.0808, 0.0806, 0.1011,\n",
       "          0.1122, 0.0989, 0.0732, 0.0969, 0.0875, 0.0814, 0.0759, 0.0610,\n",
       "          0.0636, 0.0926, 0.0798, 0.0611, 0.0953, 0.1134, 0.0627, 0.0996,\n",
       "          0.0973, 0.0743, 0.0927, 0.1119, 0.0808, 0.0647, 0.1173, 0.0816,\n",
       "          0.0538, 0.0620, 0.0780, 0.0612, 0.0544, 0.0949, 0.0739, 0.0609,\n",
       "          0.0912, 0.0961, 0.0899, 0.1099, 0.0878, 0.0792, 0.0725, 0.1145,\n",
       "          0.0718, 0.0670, 0.0927, 0.0900, 0.0969, 0.1010, 0.1065, 0.0879,\n",
       "          0.1153, 0.0771, 0.0666, 0.0792, 0.0625, 0.0749, 0.0666, 0.0647,\n",
       "          0.0717, 0.1008, 0.0835, 0.0732, 0.1067, 0.0800, 0.1113, 0.0846,\n",
       "          0.1035, 0.0723, 0.0991, 0.0943]],\n",
       "\n",
       "        [[0.0730, 0.0924, 0.0730, 0.0817, 0.0700, 0.0844, 0.1113, 0.0688,\n",
       "          0.0813, 0.0832, 0.0716, 0.0767, 0.0928, 0.1067, 0.0715, 0.0878,\n",
       "          0.0902, 0.1030, 0.0795, 0.0822, 0.0745, 0.0792, 0.0729, 0.0631,\n",
       "          0.0958, 0.0794, 0.0598, 0.0784, 0.1061, 0.0564, 0.0819, 0.0965,\n",
       "          0.0658, 0.0741, 0.0785, 0.0655, 0.0823, 0.0671, 0.0857, 0.0935,\n",
       "          0.0822, 0.1067, 0.1190, 0.0773, 0.0774, 0.0851, 0.0830, 0.0847,\n",
       "          0.0578, 0.0759, 0.0711, 0.0806, 0.0784, 0.0651, 0.1138, 0.1194,\n",
       "          0.0664, 0.0671, 0.0944, 0.1162, 0.0567, 0.0895, 0.0804, 0.0701,\n",
       "          0.0699, 0.0938, 0.0681, 0.0692, 0.0843, 0.0666, 0.0875, 0.0900,\n",
       "          0.1121, 0.0708, 0.0999, 0.1291, 0.0907, 0.0814, 0.0996, 0.0800,\n",
       "          0.0656, 0.0816, 0.0733, 0.0684, 0.0889, 0.0803, 0.0963, 0.0857,\n",
       "          0.0736, 0.1139, 0.0865, 0.0618, 0.0699, 0.0740, 0.0692, 0.0631,\n",
       "          0.0960, 0.1069, 0.0644, 0.0884]],\n",
       "\n",
       "        [[0.0479, 0.0624, 0.0654, 0.0648, 0.0618, 0.0771, 0.0699, 0.0850,\n",
       "          0.0924, 0.0743, 0.1014, 0.0815, 0.0852, 0.0959, 0.1143, 0.0520,\n",
       "          0.0840, 0.0870, 0.0645, 0.0792, 0.0667, 0.0741, 0.0671, 0.0705,\n",
       "          0.0792, 0.1000, 0.0610, 0.0833, 0.0822, 0.0627, 0.0726, 0.0987,\n",
       "          0.0870, 0.0670, 0.0702, 0.0880, 0.0972, 0.0849, 0.0964, 0.0758,\n",
       "          0.0711, 0.0927, 0.0665, 0.0636, 0.0576, 0.0592, 0.0581, 0.1046,\n",
       "          0.0680, 0.0771, 0.0822, 0.1030, 0.1125, 0.0624, 0.0878, 0.0721,\n",
       "          0.0798, 0.0653, 0.0763, 0.0911, 0.0767, 0.0715, 0.1144, 0.1180,\n",
       "          0.0590, 0.1204, 0.1197, 0.0714, 0.0794, 0.1143, 0.0694, 0.0759,\n",
       "          0.0839, 0.1116, 0.0952, 0.0693, 0.1258, 0.0896, 0.0842, 0.0721,\n",
       "          0.0888, 0.0762, 0.0700, 0.0734, 0.0690, 0.0884, 0.0825, 0.0886,\n",
       "          0.1245, 0.0989, 0.0558, 0.1106, 0.0997, 0.0688, 0.0768, 0.0693,\n",
       "          0.0738, 0.0919, 0.0831, 0.0653]],\n",
       "\n",
       "        [[0.0758, 0.0557, 0.0739, 0.0887, 0.0811, 0.1015, 0.1020, 0.0821,\n",
       "          0.0808, 0.1244, 0.0715, 0.0955, 0.0738, 0.0605, 0.0798, 0.0847,\n",
       "          0.0607, 0.0780, 0.0804, 0.0716, 0.1229, 0.0827, 0.0818, 0.1235,\n",
       "          0.0996, 0.0857, 0.0680, 0.0755, 0.0637, 0.0742, 0.0783, 0.0515,\n",
       "          0.0515, 0.0867, 0.1070, 0.0712, 0.0967, 0.0816, 0.0820, 0.1073,\n",
       "          0.0872, 0.0604, 0.0809, 0.0735, 0.0767, 0.0969, 0.0760, 0.0609,\n",
       "          0.1118, 0.0875, 0.0619, 0.0972, 0.1026, 0.0845, 0.1175, 0.0813,\n",
       "          0.0844, 0.1048, 0.1049, 0.0666, 0.0841, 0.0732, 0.0716, 0.0714,\n",
       "          0.0873, 0.0642, 0.0955, 0.0755, 0.0827, 0.1182, 0.1078, 0.0588,\n",
       "          0.0986, 0.1262, 0.0797, 0.0875, 0.0879, 0.1070, 0.0849, 0.0837,\n",
       "          0.0750, 0.0724, 0.1041, 0.1125, 0.0690, 0.0953, 0.0926, 0.0803,\n",
       "          0.0588, 0.0704, 0.0686, 0.0509, 0.0687, 0.0707, 0.0747, 0.1042,\n",
       "          0.0803, 0.0729, 0.0918, 0.1025]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffwave(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_params = ResidualParams(\n",
    "    n_residual_layers=10,\n",
    "    n_residual_channels=64,\n",
    "    dilation_cycle_length=10,\n",
    "    conditioner=ConditionerParams(\n",
    "        n_mels=16,\n",
    "    )\n",
    ")\n",
    "diffusion_params = DiffusionParams(\n",
    "    max_steps=100\n",
    ")\n",
    "diffwave = DiffWave(1, diffusion_params, residual_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0772, 0.0605, 0.0637,  ..., 0.0398, 0.0566, 0.0611]],\n",
       "\n",
       "        [[0.0732, 0.0595, 0.0742,  ..., 0.0498, 0.0558, 0.0656]],\n",
       "\n",
       "        [[0.0710, 0.0831, 0.0719,  ..., 0.0495, 0.0514, 0.0697]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0839, 0.0621, 0.0638,  ..., 0.0611, 0.0614, 0.0684]],\n",
       "\n",
       "        [[0.0718, 0.0688, 0.0551,  ..., 0.0688, 0.0648, 0.0644]],\n",
       "\n",
       "        [[0.0718, 0.0729, 0.0724,  ..., 0.0516, 0.0503, 0.0763]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 2560)\n",
    "spec = torch.randn(10, 1, 16, 10)\n",
    "\n",
    "diffwave(x, 3, spec)\n",
    "# residual_params.conditioner.upsampler(spec).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
